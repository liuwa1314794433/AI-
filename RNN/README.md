
# Recurrent Neural Network (RNN)

𝑥 - input  
𝑦 - output (prediction)  
ℎ - hidden state  

## LSTM

  - The Problem of Long-Term Dependencies

  - Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.

  - Long Short Term Memory networks (LSTM)
       a special kind of RNN, capable of learning long-term dependencies.


## Sequence translation
   - Input - sequence.
   - Output – sequence.

## Tasks
   - Handwriting to text / text to handwriting.
   - Speech to text / text to speech.
   - Machine translation.

## Input and output …
   - are NOT synchronized.
   - may have different length.
   - may have different order.
