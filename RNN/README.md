
# Recurrent Neural Network (RNN)

ğ‘¥ - input  
ğ‘¦ - output (prediction)  
â„ - hidden state  

## LSTM

  - The Problem of Long-Term Dependencies

  - Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.

  - Long Short Term Memory networks (LSTM)
       a special kind of RNN, capable of learning long-term dependencies.


## Sequence translation
   - Input - sequence.
   - Output â€“ sequence.

## Tasks
   - Handwriting to text / text to handwriting.
   - Speech to text / text to speech.
   - Machine translation.

## Input and output â€¦
   - are NOT synchronized.
   - may have different length.
   - may have different order.
